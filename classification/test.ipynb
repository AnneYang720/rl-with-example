{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(859, 1144)\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoModelForImageClassification\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('qian.jpg')\n",
    "print(image.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration. Please open a PR/issue to update `preprocessor_config.json` to use `image_processor_type` instead of `feature_extractor_type`. This warning will be removed in v4.40.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")\n",
    "# processor\n",
    "model = AutoModelForImageClassification.from_pretrained(\"microsoft/swin-tiny-patch4-window7-224\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(inputs):\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits # torch.Size([1, 1000])\n",
    "    print(\"max=\",logits.max(-1).values.item(), \", mean=\",logits.mean(-1).item())\n",
    "    predicted_class_idx = logits.argmax(-1).item()\n",
    "    print(\"Predicted class:\", model.config.id2label[predicted_class_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max= 9.424065589904785 , mean= -0.01643543876707554\n",
      "Predicted class: Egyptian cat\n"
     ]
    }
   ],
   "source": [
    "inputs = processor(images=image, return_tensors=\"pt\") # torch.Size([1, 3, 224, 224])\n",
    "inference(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max= 5.671370983123779 , mean= -0.021797088906168938\n",
      "Predicted class: langur\n"
     ]
    }
   ],
   "source": [
    "# resize image\n",
    "image2 = image.resize((224, 224))\n",
    "# add gaussian noise\n",
    "import numpy as np\n",
    "image2 = np.array(image2)\n",
    "noise = np.random.normal(0, 0, image2.shape)\n",
    "image2 = image2 + noise\n",
    "image2 = Image.fromarray(image2.astype('uint8'))\n",
    "\n",
    "# gaussian blur\n",
    "from PIL import ImageFilter\n",
    "image2 = image2.filter(ImageFilter.GaussianBlur(radius=4))\n",
    "\n",
    "image2\n",
    "\n",
    "inputs2 = processor(images=image2, return_tensors=\"pt\")\n",
    "inference(inputs2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max= 9.424065589904785 , mean= -0.01643543876707554\n",
      "Predicted class: Egyptian cat\n"
     ]
    }
   ],
   "source": [
    "image3 = image.resize((224, 224))\n",
    "\n",
    "# crop top half\n",
    "image3 = image3.crop((0, 0, 224, 224))\n",
    "image3\n",
    "\n",
    "inputs3 = processor(images=image3, return_tensors=\"pt\")\n",
    "inference(inputs3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36165cd4dc9d45188018d2a3e1e55489",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/1999 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d03169505f834660a3321b0651a176ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# load imagenet-1k test set from local tar.gz\n",
    "data_path = '/home/gyc/datasets/imagenet-tiny'\n",
    "dataset = datasets.load_dataset('imagefolder', data_dir=data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'image': <PIL.JpegImagePlugin.JpegImageFile image mode=RGB size=500x375>,\n",
       " 'label': 65,\n",
       " 'class_idx': 'n01751748',\n",
       " 'class_name': 'sea snake'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['validation'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max= 10.668045997619629 , mean= 0.010313209146261215\n",
      "Predicted class: sea snake\n"
     ]
    }
   ],
   "source": [
    "image_data = dataset['validation'][0]['image']\n",
    "\n",
    "inputs = processor(images=image_data, return_tensors=\"pt\") # torch.Size([1, 3, 224, 224])\n",
    "inference(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from classes import IMAGENET2012_CLASSES\n",
    "\n",
    "# # load imagenet-1k test set from local dir\n",
    "# data_path = '/home/gyc/datasets/imagenet-tiny/val'\n",
    "\n",
    "# import csv\n",
    "# import os\n",
    "\n",
    "# all_class_to_num = {class_name: i for i, class_name in enumerate(IMAGENET2012_CLASSES)}\n",
    "\n",
    "# with open(data_path + '/metadata.csv', 'w') as f:\n",
    "#     writer = csv.writer(f)\n",
    "#     writer.writerow(['file_name', 'label', 'class_idx', 'class_name'])\n",
    "#     for file_name in sorted(os.listdir(data_path)):\n",
    "#         if not file_name.endswith('.JPEG'):\n",
    "#             continue\n",
    "\n",
    "#         class_idx = file_name.split('_')[3].split('.')[0]\n",
    "#         class_name = IMAGENET2012_CLASSES[class_idx]\n",
    "#         class_number = all_class_to_num[class_idx]\n",
    "#         writer.writerow([file_name, class_number, class_idx, class_name])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
